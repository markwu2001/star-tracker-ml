{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Star Tracker ML Pipeline ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import os\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration values\n",
    "validation_split = 0.20\n",
    "input_size = 10\n",
    "num_epochs = 50\n",
    "batch_size = 40\n",
    "saved_model_dir = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size: 10\n",
      "Output Size: 1608\n"
     ]
    }
   ],
   "source": [
    "file = \"../images_data/mag5_adverserial_bins/mag5_adverserial_bins.csv\"\n",
    "# TODO: read the header instead of hardcoding it\n",
    "dataframe = pd.read_csv(file, header=0, names=[\"HIP\", \"bin0\", \"bin1\", \"bin2\", \"bin3\", \"bin4\", \"bin5\", \"bin6\", \"bin7\", \"bin8\", \"bin9\"])\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,1:11].astype(int)\n",
    "Y = dataset[:,0].astype(int)\n",
    "print(\"Input Size:\", len(X[0]))\n",
    "num_classes = len(np.unique(Y))\n",
    "print(\"Output Size:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(17688, 1608), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# star_labels = np.zeros(num_classes).astype(int)\\n# get labels in num_classes sized list\\n\\n# one_hot_array = dummy_Y.numpy()\\n# # print(Y[0])\\n# for i in range(len(one_hot_array)):\\n#     if star_labels[one_hot_array[i].argmax()] == 0:\\n#         star_labels[one_hot_array[i].argmax()] = Y[i]\\n# np.set_printoptions(threshold=np.inf)\\n# print(star_labels)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode class values as integers and then create dataframe with one hot encoding\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "dummy_Y = tf.one_hot(encoded_Y, depth=num_classes)\n",
    "print(dummy_Y)\n",
    "\n",
    "\n",
    "\n",
    "# Unused code from when I was sanity checking\n",
    "\"\"\"\n",
    "for i in range(100):\n",
    "    if not (encoder.classes_[dummy_Y.numpy()[i].argmax()] == Y[i]):\n",
    "        print(\"Error\")\n",
    "        # print(dummy_Y.numpy()[i].argmax())\n",
    "        # print(Y[i])\n",
    "        # print(encoder.classes_[dummy_Y.numpy()[i].argmax()])\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# star_labels = np.zeros(num_classes).astype(int)\n",
    "# get labels in num_classes sized list\n",
    "\n",
    "# one_hot_array = dummy_Y.numpy()\n",
    "# # print(Y[0])\n",
    "# for i in range(len(one_hot_array)):\n",
    "#     if star_labels[one_hot_array[i].argmax()] == 0:\n",
    "#         star_labels[one_hot_array[i].argmax()] = Y[i]\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "# print(star_labels)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ML Model\n",
    "star_model = tf.keras.Sequential([\n",
    "  layers.Dense(input_size, activation=\"relu\", name=\"layer1\"),\n",
    "  layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
    "  layers.Dense(32, activation=\"relu\", name=\"layer3\"),\n",
    "  layers.Dense(1608, activation=\"softmax\", name =\"layer4\")\n",
    "])\n",
    "\n",
    "star_model.compile(loss = \"categorical_crossentropy\",\n",
    "                      optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1719977164.184571  113436 service.cc:145] XLA service 0x7fc0c0004c30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1719977164.184762  113436 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-07-02 20:26:04.235318: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-02 20:26:04.413449: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1719977165.479121  125136 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_376', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1719977165.624499  125132 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_376', 304 bytes spill stores, 304 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m112/553\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0016 - loss: 7.4054  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1719977166.797750  113436 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m552/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0202 - loss: 6.7107"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1719977168.384025  125244 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_376', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n",
      "I0000 00:00:1719977168.450889  125245 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_376', 300 bytes spill stores, 300 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.0203 - loss: 6.7065\n",
      "Epoch 2/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3303 - loss: 2.5954\n",
      "Epoch 3/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5934 - loss: 1.3788\n",
      "Epoch 4/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7382 - loss: 0.8657\n",
      "Epoch 5/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8086 - loss: 0.6364\n",
      "Epoch 6/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8507 - loss: 0.4967\n",
      "Epoch 7/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.4480\n",
      "Epoch 8/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8871 - loss: 0.3906\n",
      "Epoch 9/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.3500\n",
      "Epoch 10/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9003 - loss: 0.3287\n",
      "Epoch 11/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9054 - loss: 0.3293\n",
      "Epoch 12/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2859\n",
      "Epoch 13/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9210 - loss: 0.2606\n",
      "Epoch 14/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.2595\n",
      "Epoch 15/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.2392\n",
      "Epoch 16/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9320 - loss: 0.2383\n",
      "Epoch 17/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9355 - loss: 0.2304\n",
      "Epoch 18/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.2090\n",
      "Epoch 19/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9474 - loss: 0.1749\n",
      "Epoch 20/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.2212\n",
      "Epoch 21/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9524 - loss: 0.1700\n",
      "Epoch 22/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.1718\n",
      "Epoch 23/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9414 - loss: 0.2076\n",
      "Epoch 24/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9648 - loss: 0.1255\n",
      "Epoch 25/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9440 - loss: 0.1958\n",
      "Epoch 26/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.1555\n",
      "Epoch 27/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9466 - loss: 0.1805\n",
      "Epoch 28/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9615 - loss: 0.1317\n",
      "Epoch 29/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9606 - loss: 0.1442\n",
      "Epoch 30/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9595 - loss: 0.1449\n",
      "Epoch 31/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9573 - loss: 0.1537\n",
      "Epoch 32/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9616 - loss: 0.1270\n",
      "Epoch 33/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9651 - loss: 0.1210\n",
      "Epoch 34/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9617 - loss: 0.1365\n",
      "Epoch 35/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.1472\n",
      "Epoch 36/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.1108\n",
      "Epoch 37/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9659 - loss: 0.1147\n",
      "Epoch 38/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9669 - loss: 0.1156\n",
      "Epoch 39/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9612 - loss: 0.1361\n",
      "Epoch 40/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1041\n",
      "Epoch 41/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9727 - loss: 0.0949\n",
      "Epoch 42/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.1070\n",
      "Epoch 43/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9734 - loss: 0.0836\n",
      "Epoch 44/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9721 - loss: 0.0911\n",
      "Epoch 45/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 0.1105\n",
      "Epoch 46/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9675 - loss: 0.0999\n",
      "Epoch 47/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.1066\n",
      "Epoch 48/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9762 - loss: 0.0777\n",
      "Epoch 49/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9786 - loss: 0.0746\n",
      "Epoch 50/50\n",
      "\u001b[1m553/553\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9683 - loss: 0.1104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fc114385b10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training\n",
    "star_model.fit(X, dummy_Y, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/star_tracker_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/star_tracker_saved_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'models/star_tracker_saved_model/'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1608), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140468450171136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140470127857152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140470127856976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140467243647216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140467243655312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140467243651440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140467243660592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140467243661648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1719977882.345787  113281 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1719977882.345828  113281 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2024-07-02 20:38:02.346039: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: models/star_tracker_saved_model/\n",
      "2024-07-02 20:38:02.346465: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-07-02 20:38:02.346472: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: models/star_tracker_saved_model/\n",
      "2024-07-02 20:38:02.351013: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2024-07-02 20:38:02.369465: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: models/star_tracker_saved_model/\n",
      "2024-07-02 20:38:02.374925: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 28888 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "\n",
    "star_model.save(saved_model_dir + 'star_tracker_model_large.keras')\n",
    "if not os.path.exists(saved_model_dir + 'star_tracker_saved_model/'):\n",
    "    os.makedirs(saved_model_dir + 'star_tracker_saved_model/')\n",
    "star_model.export(saved_model_dir + 'star_tracker_saved_model/')\n",
    "\n",
    "# TODO: tflite conversion is not working.\n",
    "# # Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir + 'star_tracker_saved_model/') # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# # Save the model.\n",
    "with open(saved_model_dir + 'star_tracker_model_small.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
