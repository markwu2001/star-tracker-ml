{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Star Tracker ML Pipeline ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import os\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filepaths and Hyperparameters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data filepath for training\n",
    "file = \"../images_data/mag5_1608_47deg_gray/bins/mag5_1608_47deg_bin_features.csv\"          # <-- Configure together\n",
    "file_descript = \"mag5_1608_47deg\"     # Magnitude of stars, num classes, camera fov         # <-- Configure together\n",
    "\n",
    "# Configuration values\n",
    "validation_split = 0.20\n",
    "num_epochs = 100\n",
    "batch_size = 40\n",
    "saved_model_dir = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size: 10\n",
      "Output Size: 1608\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: read the header instead of hardcoding it\n",
    "dataframe = pd.read_csv(file, header=0)\n",
    "input_size = len(dataframe.columns) - 1\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,1:(input_size+1)].astype(int)\n",
    "Y = dataset[:,0].astype(int)\n",
    "print(\"Input Size:\", len(X[0]))\n",
    "num_classes = len(np.unique(Y))\n",
    "print(\"Output Size:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 13:25:53.284134: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-07 13:25:53.404220: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-07 13:25:53.404281: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-07 13:25:53.406422: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-07 13:25:53.406478: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-07 13:25:53.406516: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-07 13:25:53.626805: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-07 13:25:53.627016: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-07 13:25:53.627025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-07 13:25:53.627079: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-07 13:25:53.627692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5557 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:07:00.0, compute capability: 8.6\n",
      "2024-07-07 13:25:53.820232: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 3113139456 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(484008, 1608), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# star_labels = np.zeros(num_classes).astype(int)\\n# get labels in num_classes sized list\\n\\n# one_hot_array = dummy_Y.numpy()\\n# # print(Y[0])\\n# for i in range(len(one_hot_array)):\\n#     if star_labels[one_hot_array[i].argmax()] == 0:\\n#         star_labels[one_hot_array[i].argmax()] = Y[i]\\n# np.set_printoptions(threshold=np.inf)\\n# print(star_labels)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode class values as integers and then create dataframe with one hot encoding\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "dummy_Y = tf.one_hot(encoded_Y, depth=num_classes)\n",
    "print(dummy_Y)\n",
    "\n",
    "\n",
    "\n",
    "# Unused code from when I was sanity checking\n",
    "\"\"\"\n",
    "for i in range(100):\n",
    "    if not (encoder.classes_[dummy_Y.numpy()[i].argmax()] == Y[i]):\n",
    "        print(\"Error\")\n",
    "        # print(dummy_Y.numpy()[i].argmax())\n",
    "        # print(Y[i])\n",
    "        # print(encoder.classes_[dummy_Y.numpy()[i].argmax()])\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# star_labels = np.zeros(num_classes).astype(int)\n",
    "# get labels in num_classes sized list\n",
    "\n",
    "# one_hot_array = dummy_Y.numpy()\n",
    "# # print(Y[0])\n",
    "# for i in range(len(one_hot_array)):\n",
    "#     if star_labels[one_hot_array[i].argmax()] == 0:\n",
    "#         star_labels[one_hot_array[i].argmax()] = Y[i]\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "# print(star_labels)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ML Model\n",
    "star_model = tf.keras.Sequential([\n",
    "  layers.Dense(input_size, activation=\"relu\", name=\"layer1\"),\n",
    "  layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
    "  layers.Dense(128, activation=\"relu\", name=\"layer3\"),\n",
    "  layers.Dense(1608, activation=\"softmax\", name =\"layer4\")\n",
    "])\n",
    "\n",
    "star_model.compile(loss = \"categorical_crossentropy\",\n",
    "                      optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-07 13:26:32.753606: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 38720640 exceeds 10% of free system memory.\n",
      "2024-07-07 13:26:32.787700: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 38720640 exceeds 10% of free system memory.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720383993.633384   17791 service.cc:145] XLA service 0x7fa13c00a190 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1720383993.633693   17791 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Ti, Compute Capability 8.6\n",
      "2024-07-07 13:26:33.685348: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-07 13:26:33.856796: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720383994.719908   17967 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_376', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1720383994.813913   17966 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_376', 304 bytes spill stores, 304 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   90/15126\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - accuracy: 0.0030 - loss: 7.6325      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720383997.487069   17791 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15121/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7456 - loss: 1.2540"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720384028.894340   18197 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_376', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step - accuracy: 0.7457 - loss: 1.2537\n",
      "Epoch 2/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9635 - loss: 0.1269\n",
      "Epoch 3/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0911\n",
      "Epoch 4/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9754 - loss: 0.0765\n",
      "Epoch 5/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0677\n",
      "Epoch 6/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0643\n",
      "Epoch 7/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.0596\n",
      "Epoch 8/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0568\n",
      "Epoch 9/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9806 - loss: 0.0556\n",
      "Epoch 10/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9806 - loss: 0.0552\n",
      "Epoch 11/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9810 - loss: 0.0546\n",
      "Epoch 12/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9813 - loss: 0.0521\n",
      "Epoch 13/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9814 - loss: 0.0516\n",
      "Epoch 14/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9819 - loss: 0.0503\n",
      "Epoch 15/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9821 - loss: 0.0497\n",
      "Epoch 16/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9824 - loss: 0.0482\n",
      "Epoch 17/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9823 - loss: 0.0489\n",
      "Epoch 18/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0491\n",
      "Epoch 19/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0481\n",
      "Epoch 20/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.0470\n",
      "Epoch 21/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0470\n",
      "Epoch 22/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0467\n",
      "Epoch 23/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0466\n",
      "Epoch 24/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9826 - loss: 0.0482\n",
      "Epoch 25/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0481\n",
      "Epoch 26/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0467\n",
      "Epoch 27/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0477\n",
      "Epoch 28/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9831 - loss: 0.0478\n",
      "Epoch 29/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9836 - loss: 0.0461\n",
      "Epoch 30/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0465\n",
      "Epoch 31/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0467\n",
      "Epoch 32/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0480\n",
      "Epoch 33/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0480\n",
      "Epoch 34/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9832 - loss: 0.0482\n",
      "Epoch 35/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0460\n",
      "Epoch 36/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9837 - loss: 0.0475\n",
      "Epoch 37/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0471\n",
      "Epoch 38/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0476\n",
      "Epoch 39/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0478\n",
      "Epoch 40/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0475\n",
      "Epoch 41/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0470\n",
      "Epoch 42/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0473\n",
      "Epoch 43/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0468\n",
      "Epoch 44/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0475\n",
      "Epoch 45/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0487\n",
      "Epoch 46/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0469\n",
      "Epoch 47/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0485\n",
      "Epoch 48/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9835 - loss: 0.0490\n",
      "Epoch 49/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0467\n",
      "Epoch 50/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0483\n",
      "Epoch 51/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0485\n",
      "Epoch 52/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0480\n",
      "Epoch 53/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0481\n",
      "Epoch 54/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0480\n",
      "Epoch 55/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0495\n",
      "Epoch 56/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0491\n",
      "Epoch 57/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0477\n",
      "Epoch 58/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0502\n",
      "Epoch 59/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0487\n",
      "Epoch 60/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0486\n",
      "Epoch 61/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0486\n",
      "Epoch 62/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0500\n",
      "Epoch 63/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0472\n",
      "Epoch 64/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0499\n",
      "Epoch 65/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0499\n",
      "Epoch 66/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0481\n",
      "Epoch 67/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0508\n",
      "Epoch 68/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0498\n",
      "Epoch 69/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9838 - loss: 0.0484\n",
      "Epoch 70/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0498\n",
      "Epoch 71/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0479\n",
      "Epoch 72/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9840 - loss: 0.0503\n",
      "Epoch 73/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0491\n",
      "Epoch 74/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0500\n",
      "Epoch 75/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9850 - loss: 0.0482\n",
      "Epoch 76/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0502\n",
      "Epoch 77/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0485\n",
      "Epoch 78/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0481\n",
      "Epoch 79/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0505\n",
      "Epoch 80/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0509\n",
      "Epoch 81/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0500\n",
      "Epoch 82/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9841 - loss: 0.0525\n",
      "Epoch 83/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0507\n",
      "Epoch 84/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0505\n",
      "Epoch 85/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0518\n",
      "Epoch 86/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9845 - loss: 0.0508\n",
      "Epoch 87/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0503\n",
      "Epoch 88/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0520\n",
      "Epoch 89/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0526\n",
      "Epoch 90/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0509\n",
      "Epoch 91/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0508\n",
      "Epoch 92/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0499\n",
      "Epoch 93/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0520\n",
      "Epoch 94/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0513\n",
      "Epoch 95/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0504\n",
      "Epoch 96/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9843 - loss: 0.0546\n",
      "Epoch 97/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9842 - loss: 0.0518\n",
      "Epoch 98/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0498\n",
      "Epoch 99/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9846 - loss: 0.0538\n",
      "Epoch 100/100\n",
      "\u001b[1m15126/15126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fa21e3fe740>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training\n",
    "star_model.fit(X, dummy_Y, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ layer1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1608</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">207,432</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ layer1 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer2 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer3 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ layer4 (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1608\u001b[0m)           │       \u001b[38;5;34m207,432\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">649,700</span> (2.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m649,700\u001b[0m (2.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">216,566</span> (845.96 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m216,566\u001b[0m (845.96 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">433,134</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m433,134\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mag5_1608_47deg_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mag5_1608_47deg_saved_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'models/mag5_1608_47deg_saved_model/'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1608), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  140334234585920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140334234594192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140334234597184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140334234800144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140334234807008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140334234808416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140334234807536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  140334235030928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1720387154.343746   17409 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1720387154.343779   17409 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2024-07-07 14:19:14.344679: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: models/mag5_1608_47deg_saved_model/\n",
      "2024-07-07 14:19:14.345130: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-07-07 14:19:14.345138: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: models/mag5_1608_47deg_saved_model/\n",
      "2024-07-07 14:19:14.353097: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-07-07 14:19:14.353911: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2024-07-07 14:19:14.378204: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: models/mag5_1608_47deg_saved_model/\n",
      "2024-07-07 14:19:14.385048: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 40373 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "star_model.summary()\n",
    "\n",
    "star_model.save(saved_model_dir + file_descript +'.keras')\n",
    "if not os.path.exists(saved_model_dir + file_descript +'_saved_model/'):\n",
    "    os.makedirs(saved_model_dir + file_descript +'_saved_model/')\n",
    "star_model.export(saved_model_dir + file_descript +'_saved_model/')\n",
    "\n",
    "# TODO: tflite conversion is not working.\n",
    "# # Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir + file_descript +'_saved_model/') # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# # Save the model.\n",
    "with open(saved_model_dir + file_descript + '_small.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
