{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Star Tracker ML Pipeline ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 16:37:56.147069: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-03 16:37:57.260483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import os\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filepaths and Hyperparameters ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data filepath for training\n",
    "file = \"../images_data/mag5_1608_47deg_gray/bins/mag5_1608_47deg_bin_features.csv\"          # <-- Configure together\n",
    "file_descript = \"mag5_1608_47deg\"     # Magnitude of stars, num classes, camera fov         # <-- Configure together\n",
    "\n",
    "# Configuration values\n",
    "validation_split = 0.20\n",
    "num_epochs = 60\n",
    "batch_size = 40\n",
    "saved_model_dir = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size: 10\n",
      "Output Size: 1608\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: read the header instead of hardcoding it\n",
    "dataframe = pd.read_csv(file, header=0)\n",
    "input_size = len(dataframe.columns) - 1\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,1:(input_size+1)].astype(int)\n",
    "Y = dataset[:,0].astype(int)\n",
    "print(\"Input Size:\", len(X[0]))\n",
    "num_classes = len(np.unique(Y))\n",
    "print(\"Output Size:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 16:38:00.075175: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-03 16:38:00.484594: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-03 16:38:00.484672: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-03 16:38:00.501777: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape=(65928, 1608), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 16:38:00.501902: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-03 16:38:00.501950: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-03 16:38:01.611943: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-03 16:38:01.612009: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-03 16:38:01.612018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-07-03 16:38:01.612061: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-07-03 16:38:01.612112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-07-03 16:38:01.802384: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 424048896 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# star_labels = np.zeros(num_classes).astype(int)\\n# get labels in num_classes sized list\\n\\n# one_hot_array = dummy_Y.numpy()\\n# # print(Y[0])\\n# for i in range(len(one_hot_array)):\\n#     if star_labels[one_hot_array[i].argmax()] == 0:\\n#         star_labels[one_hot_array[i].argmax()] = Y[i]\\n# np.set_printoptions(threshold=np.inf)\\n# print(star_labels)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode class values as integers and then create dataframe with one hot encoding\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "\n",
    "dummy_Y = tf.one_hot(encoded_Y, depth=num_classes)\n",
    "print(dummy_Y)\n",
    "\n",
    "\n",
    "\n",
    "# Unused code from when I was sanity checking\n",
    "\"\"\"\n",
    "for i in range(100):\n",
    "    if not (encoder.classes_[dummy_Y.numpy()[i].argmax()] == Y[i]):\n",
    "        print(\"Error\")\n",
    "        # print(dummy_Y.numpy()[i].argmax())\n",
    "        # print(Y[i])\n",
    "        # print(encoder.classes_[dummy_Y.numpy()[i].argmax()])\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# star_labels = np.zeros(num_classes).astype(int)\n",
    "# get labels in num_classes sized list\n",
    "\n",
    "# one_hot_array = dummy_Y.numpy()\n",
    "# # print(Y[0])\n",
    "# for i in range(len(one_hot_array)):\n",
    "#     if star_labels[one_hot_array[i].argmax()] == 0:\n",
    "#         star_labels[one_hot_array[i].argmax()] = Y[i]\n",
    "# np.set_printoptions(threshold=np.inf)\n",
    "# print(star_labels)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ML Model\n",
    "star_model = tf.keras.Sequential([\n",
    "  layers.Dense(input_size, activation=\"relu\", name=\"layer1\"),\n",
    "  layers.Dense(64, activation=\"relu\", name=\"layer2\"),\n",
    "  layers.Dense(32, activation=\"relu\", name=\"layer3\"),\n",
    "  layers.Dense(1608, activation=\"softmax\", name =\"layer4\")\n",
    "])\n",
    "\n",
    "star_model.compile(loss = \"categorical_crossentropy\",\n",
    "                      optimizer = 'adam', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720049882.901514  129220 service.cc:145] XLA service 0x7f3538004e00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1720049882.901599  129220 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-07-03 16:38:02.933693: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-03 16:38:03.112387: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720049884.304134  129275 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_376', 48 bytes spill stores, 48 bytes spill loads\n",
      "\n",
      "I0000 00:00:1720049884.330152  129273 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_376', 304 bytes spill stores, 304 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 106/2061\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.0018 - loss: 7.3792"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720049885.251217  129220 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2045/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.0853 - loss: 5.3296"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1720049888.487771  129400 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'triton_gemm_dot_376', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.0862 - loss: 5.3168\n",
      "Epoch 2/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5024 - loss: 1.6869\n",
      "Epoch 3/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7234 - loss: 0.9074\n",
      "Epoch 4/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8065 - loss: 0.6313\n",
      "Epoch 5/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8443 - loss: 0.5117\n",
      "Epoch 6/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8631 - loss: 0.4515\n",
      "Epoch 7/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.3850\n",
      "Epoch 8/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8922 - loss: 0.3583\n",
      "Epoch 9/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.3294\n",
      "Epoch 10/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.3171\n",
      "Epoch 11/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2935\n",
      "Epoch 12/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2788\n",
      "Epoch 13/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9209 - loss: 0.2519\n",
      "Epoch 14/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2483\n",
      "Epoch 15/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.2438\n",
      "Epoch 16/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2348\n",
      "Epoch 17/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9293 - loss: 0.2275\n",
      "Epoch 18/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9323 - loss: 0.2137\n",
      "Epoch 19/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9341 - loss: 0.2082\n",
      "Epoch 20/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9353 - loss: 0.2023\n",
      "Epoch 21/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.1967\n",
      "Epoch 22/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9393 - loss: 0.1933\n",
      "Epoch 23/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9401 - loss: 0.1857\n",
      "Epoch 24/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9384 - loss: 0.1895\n",
      "Epoch 25/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.1785\n",
      "Epoch 26/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9423 - loss: 0.1789\n",
      "Epoch 27/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9444 - loss: 0.1798\n",
      "Epoch 28/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9424 - loss: 0.1710\n",
      "Epoch 29/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9453 - loss: 0.1682\n",
      "Epoch 30/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9458 - loss: 0.1672\n",
      "Epoch 31/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9462 - loss: 0.1617\n",
      "Epoch 32/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9493 - loss: 0.1581\n",
      "Epoch 33/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9497 - loss: 0.1507\n",
      "Epoch 34/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9481 - loss: 0.1570\n",
      "Epoch 35/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9491 - loss: 0.1533\n",
      "Epoch 36/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9486 - loss: 0.1544\n",
      "Epoch 37/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9489 - loss: 0.1532\n",
      "Epoch 38/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.1447\n",
      "Epoch 39/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9510 - loss: 0.1433\n",
      "Epoch 40/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9529 - loss: 0.1402\n",
      "Epoch 41/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9521 - loss: 0.1445\n",
      "Epoch 42/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9518 - loss: 0.1449\n",
      "Epoch 43/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9511 - loss: 0.1457\n",
      "Epoch 44/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1392\n",
      "Epoch 45/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9545 - loss: 0.1357\n",
      "Epoch 46/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9560 - loss: 0.1324\n",
      "Epoch 47/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.1305\n",
      "Epoch 48/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9541 - loss: 0.1326\n",
      "Epoch 49/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1257\n",
      "Epoch 50/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9553 - loss: 0.1294\n",
      "Epoch 51/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9548 - loss: 0.1325\n",
      "Epoch 52/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9565 - loss: 0.1257\n",
      "Epoch 53/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9562 - loss: 0.1278\n",
      "Epoch 54/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9556 - loss: 0.1274\n",
      "Epoch 55/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9550 - loss: 0.1284\n",
      "Epoch 56/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9573 - loss: 0.1264\n",
      "Epoch 57/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9594 - loss: 0.1193\n",
      "Epoch 58/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9570 - loss: 0.1248\n",
      "Epoch 59/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9584 - loss: 0.1214\n",
      "Epoch 60/60\n",
      "\u001b[1m2061/2061\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.1114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f36481b3fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training\n",
    "star_model.fit(X, dummy_Y, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mag5_1608_47deg_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/mag5_1608_47deg_saved_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'models/mag5_1608_47deg_saved_model/'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1608), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  139871074915552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139871074923824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139871074912384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139871059007920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139871059005104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139871059017424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139871074917664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139871059271472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1720050176.203430  129083 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1720050176.203467  129083 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2024-07-03 16:42:56.203661: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: models/mag5_1608_47deg_saved_model/\n",
      "2024-07-03 16:42:56.203993: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-07-03 16:42:56.204003: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: models/mag5_1608_47deg_saved_model/\n",
      "2024-07-03 16:42:56.208258: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2024-07-03 16:42:56.227455: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: models/mag5_1608_47deg_saved_model/\n",
      "2024-07-03 16:42:56.233408: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 29750 microseconds.\n"
     ]
    }
   ],
   "source": [
    "# Save Model\n",
    "\n",
    "star_model.save(saved_model_dir + file_descript +'.keras')\n",
    "if not os.path.exists(saved_model_dir + file_descript +'_saved_model/'):\n",
    "    os.makedirs(saved_model_dir + file_descript +'_saved_model/')\n",
    "star_model.export(saved_model_dir + file_descript +'_saved_model/')\n",
    "\n",
    "# TODO: tflite conversion is not working.\n",
    "# # Convert the model\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir + file_descript +'_saved_model/') # path to the SavedModel directory\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# # Save the model.\n",
    "with open(saved_model_dir + file_descript + '_small.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
